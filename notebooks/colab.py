# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mhn7cYYmKrUqgevzOhdvTk4TBQr-swxV
"""

# !git clone https://github.com/andreclaudino/claudino-gpt-v2.git
# !pip install -e claudino-gpt-v2
# !cp -r claudino-gpt-v2/src/claudino_gpt claudino_gpt
# !cp -r claudino-gpt-v2/resources resources

# Dados brutos
raw_seed = 123456789
train_test_split_ratio = 0.2

source_preprocessing_path = "resources/materias_raw.csv"
raw_feature_column_name = "conteudo_noticia"
tokenizer_preprocessing_output_path = "outputs/tokenizer_preprocessing"

# Tokenizador
vocabulary_size = 50000
tokenizer_data_source_path = "outputs/tokenizer_preprocessing/train.json"

# Modelo
train_data_source_path = "outputs/tokenizer_preprocessing/train.json"
validation_data_source_path = "outputs/tokenizer_preprocessing/validation.json"
feature_column_name = "conteudo_noticia"
tokenizer_path = "outputs/tokenizer"

import tensorflow as tf
from transformers import GPT2Tokenizer

from claudino_gpt.feature_engineering.tokenization import extract_features_for_tokenizer
from claudino_gpt.persistence.preprocessing import load_proceprocessing_raw_data, save_preprocessing_dataframe
from claudino_gpt.models.tokenizer import ClaudinoGPTTokenizer

from claudino_gpt.persistence.model_data import load_training_data
from claudino_gpt.models.claudino_gpt import ClaudinoGPT

raw_preprocessing_dataframe = load_proceprocessing_raw_data(source_preprocessing_path, raw_seed, train_test_split_ratio)
tokenizer_features_dataframe = extract_features_for_tokenizer(raw_preprocessing_dataframe, raw_feature_column_name)
save_preprocessing_dataframe(tokenizer_features_dataframe, tokenizer_preprocessing_output_path)



tokenizer = ClaudinoGPTTokenizer(vocabulary_size)
tokenizer.train(tokenizer_data_source_path)
tokenizer.save("outputs/tokenizer")

tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)

# Loop

block_size = 128
BATCH_SIZE = 16
BUFFER_SIZE = 1000
num_epoch = 5

tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir='trained/tensorboard-dir',
    histogram_freq=0,
    write_graph=True,
    write_images=True
)

model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath="trained/checkpoints",
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

training_callbacks = [
    tensorboard_callback,
    model_checkpoint_callback
]


dataset_treino = load_training_data(
    train_data_source_path,
    feature_column_name,
    block_size,
    tokenizer
)

dataset_validacao = load_training_data(
    validation_data_source_path,
    feature_column_name,
    block_size,
    tokenizer
)


# %%
model = ClaudinoGPT(tokenizer)
# defining our optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4, epsilon=1e-08, clipnorm=1.0)
# definining our loss function
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
# defining our metric which we want to observe
metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')
# compiling the model
model.compile(
    optimizer=optimizer,
    loss=[loss, *[None] * model.config.n_layer],
    metrics=[metric]
)

history = model.fit(
    x=dataset_treino,
    epochs=num_epoch,
    callbacks=training_callbacks,
    validation_data=dataset_validacao,
)

